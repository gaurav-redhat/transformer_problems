{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lecture 10: MCUNet & TinyML\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gaurav-redhat/transformer_problems/blob/efficientml-course/efficientml_course/10_mcunet_tinyml/demo.ipynb)\n",
        "\n",
        "Running ML on microcontrollers with 256KB RAM!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install torch -q\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# MCU Memory Constraints\n",
        "MCU_CONSTRAINTS = {\n",
        "    'STM32F746': {'sram': 320, 'flash': 1024},  # KB\n",
        "    'Arduino Nano 33': {'sram': 256, 'flash': 1024},\n",
        "    'ESP32': {'sram': 520, 'flash': 4096},\n",
        "}\n",
        "\n",
        "def calculate_peak_memory(model, input_size, dtype_bytes=1):\n",
        "    \"\"\"Estimate peak memory during inference (activations)\"\"\"\n",
        "    # Simplified: max activation size across layers\n",
        "    x = torch.randn(1, *input_size)\n",
        "    max_activation = 0\n",
        "    \n",
        "    def hook(module, input, output):\n",
        "        nonlocal max_activation\n",
        "        if isinstance(output, torch.Tensor):\n",
        "            max_activation = max(max_activation, output.numel())\n",
        "    \n",
        "    hooks = []\n",
        "    for module in model.modules():\n",
        "        hooks.append(module.register_forward_hook(hook))\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        model(x)\n",
        "    \n",
        "    for h in hooks:\n",
        "        h.remove()\n",
        "    \n",
        "    return max_activation * dtype_bytes / 1024  # KB\n",
        "\n",
        "# Tiny model for MCU\n",
        "class TinyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 8, 3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(8, 16, 3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "        self.classifier = nn.Linear(16, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return self.classifier(x.view(x.size(0), -1))\n",
        "\n",
        "model = TinyNet()\n",
        "param_kb = sum(p.numel() for p in model.parameters()) / 1024\n",
        "activation_kb = calculate_peak_memory(model, (3, 48, 48))\n",
        "\n",
        "print(\"TinyNet for MCU:\")\n",
        "print(f\"  Parameters: {param_kb:.1f} KB\")\n",
        "print(f\"  Peak activation: {activation_kb:.1f} KB\")\n",
        "print(f\"  Total: {param_kb + activation_kb:.1f} KB\")\n",
        "print(f\"\\n  Fits on STM32F746 (320KB SRAM)? {'Yes!' if param_kb + activation_kb < 320 else 'No'}\")\n",
        "print(\"\\nðŸŽ¯ TinyML requires extreme memory optimization!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
