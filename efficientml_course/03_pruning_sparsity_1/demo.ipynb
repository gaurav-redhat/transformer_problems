{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lecture 3: Pruning & Sparsity (Part I)\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gaurav-redhat/transformer_problems/blob/efficientml-course/efficientml_course/03_pruning_sparsity_1/demo.ipynb)\n",
        "\n",
        "Implementing magnitude pruning to remove 90% of weights!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install torch torchvision -q\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.utils.prune as prune\n",
        "\n",
        "# Create a simple model\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(784, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 10)\n",
        ")\n",
        "\n",
        "# Count parameters before pruning\n",
        "def count_nonzero(model):\n",
        "    total = 0\n",
        "    nonzero = 0\n",
        "    for p in model.parameters():\n",
        "        total += p.numel()\n",
        "        nonzero += (p != 0).sum().item()\n",
        "    return nonzero, total\n",
        "\n",
        "before_nz, before_total = count_nonzero(model)\n",
        "print(f\"Before pruning: {before_nz:,} / {before_total:,} non-zero ({100*before_nz/before_total:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply magnitude pruning - remove smallest 90% of weights\n",
        "for name, module in model.named_modules():\n",
        "    if isinstance(module, nn.Linear):\n",
        "        prune.l1_unstructured(module, name='weight', amount=0.9)\n",
        "        prune.remove(module, 'weight')  # Make pruning permanent\n",
        "\n",
        "after_nz, after_total = count_nonzero(model)\n",
        "print(f\"After 90% pruning: {after_nz:,} / {after_total:,} non-zero ({100*after_nz/after_total:.1f}%)\")\n",
        "print(f\"\\nðŸŽ¯ Removed {100*(1-after_nz/before_nz):.1f}% of weights!\")\n",
        "\n",
        "# Visualize sparsity\n",
        "import matplotlib.pyplot as plt\n",
        "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
        "for i, (name, module) in enumerate([(n, m) for n, m in model.named_modules() if isinstance(m, nn.Linear)]):\n",
        "    w = module.weight.data.cpu().numpy()\n",
        "    axes[i].imshow(w != 0, cmap='binary', aspect='auto')\n",
        "    axes[i].set_title(f'Layer {i+1}: {(w != 0).sum()}/{w.size} non-zero')\n",
        "plt.suptitle('Sparse Weight Matrices (white = zero)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
