{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lecture 8: Neural Architecture Search (Part II) - Hardware-Aware\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gaurav-redhat/transformer_problems/blob/efficientml-course/efficientml_course/08_neural_architecture_search_2/demo.ipynb)\n",
        "\n",
        "Hardware-aware NAS with latency lookup tables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install torch -q\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Hardware-Aware NAS: Include latency in the loss!\n",
        "# Latency lookup table (pre-measured on target device)\n",
        "LATENCY_TABLE = {\n",
        "    'conv3x3': 1.2,   # ms\n",
        "    'conv5x5': 2.8,\n",
        "    'conv7x7': 5.1,\n",
        "    'dwconv3x3': 0.3,\n",
        "    'dwconv5x5': 0.5,\n",
        "    'skip': 0.0,\n",
        "}\n",
        "\n",
        "class HardwareAwareMixedOp(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super().__init__()\n",
        "        self.ops = nn.ModuleDict({\n",
        "            'conv3x3': nn.Conv2d(channels, channels, 3, padding=1),\n",
        "            'conv5x5': nn.Conv2d(channels, channels, 5, padding=2),\n",
        "            'dwconv3x3': nn.Conv2d(channels, channels, 3, padding=1, groups=channels),\n",
        "            'skip': nn.Identity(),\n",
        "        })\n",
        "        self.alpha = nn.Parameter(torch.zeros(len(self.ops)))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        weights = F.softmax(self.alpha, dim=0)\n",
        "        return sum(w * self.ops[name](x) for w, name in zip(weights, self.ops.keys()))\n",
        "    \n",
        "    def get_latency(self):\n",
        "        \"\"\"Differentiable latency estimation\"\"\"\n",
        "        weights = F.softmax(self.alpha, dim=0)\n",
        "        latency = sum(w * LATENCY_TABLE.get(name, 1.0) \n",
        "                     for w, name in zip(weights, self.ops.keys()))\n",
        "        return latency\n",
        "\n",
        "# Demo\n",
        "op = HardwareAwareMixedOp(64)\n",
        "print(\"Hardware-Aware NAS Loss:\")\n",
        "print(f\"  Expected latency: {op.get_latency():.2f} ms\")\n",
        "print(\"\\nLoss = CE_loss + lambda * latency_loss\")\n",
        "print(\"ðŸŽ¯ This makes NAS optimize for both accuracy AND speed!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
